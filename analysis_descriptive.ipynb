{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run analysis__setup.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Parsed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_full.to_csv(ANALYSIS_OUTPUT_DIR / \"df_agg_full.csv.gz\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data by Fairness Grouping\n",
    "\n",
    "Most analyses only make sense for one value of fairness grouping, so we explicitly filter the data here to use one of the two values and create a new dataframe that holds the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_agg_full[df_agg_full[\"sett_eval_fairness_grouping\"] == \"majority-minority\"]\n",
    "rows, columns = df_agg.shape\n",
    "print(f\"The data has N = {rows} rows and N = {columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(df_agg_full, x=\"fair_main_equalized_odds_difference\", marginal=\"rug\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(df_agg_full, x=\"fair_main_equalized_odds_difference\", color=\"sett_eval_fairness_grouping\", marginal=\"rug\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_full[\"sett_eval_fairness_grouping\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Helper Function to get interactive refreshing dropdowns\n",
    "def interactive_single_var_dropdown(options, render_function, description='Column:'):\n",
    "    dd = widgets.Dropdown(\n",
    "        options=options,\n",
    "        description=description,\n",
    "    )\n",
    "\n",
    "    def refresh():\n",
    "        display(dd)\n",
    "\n",
    "        render_function(dd.value)\n",
    "\n",
    "    def on_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            clear_output()\n",
    "\n",
    "            refresh()\n",
    "\n",
    "    dd.observe(on_change)\n",
    "\n",
    "    refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_simple_density(colname):\n",
    "    # Show default density plot\n",
    "    df_agg[colname].plot.kde()\n",
    "\n",
    "interactive_single_var_dropdown(options = cols_fairness + cols_performance, render_function=render_simple_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def render_plotly_density(colname):\n",
    "    fig = px.histogram(\n",
    "        df_agg,\n",
    "        x=colname,\n",
    "        marginal=\"rug\",\n",
    "        hover_data=cols_settings\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "interactive_single_var_dropdown(options = cols_fairness + cols_performance, render_function=render_plotly_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    df_agg,\n",
    "    x=\"perf_ovrl_accuracy\",\n",
    "    y=main_fairness_metric,\n",
    "    marginal_x=\"violin\",\n",
    "    marginal_y= \"violin\",\n",
    "    hover_data=cols_settings,\n",
    "    title=\"Accuracy x Fairness\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis of Fairness based on Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def fairness_violin(column_to_compare):\n",
    "    fig = px.violin(\n",
    "        df_agg,\n",
    "        x = column_to_compare,\n",
    "        y = main_fairness_metric,\n",
    "        color = column_to_compare,\n",
    "        points = \"all\",\n",
    "        hover_data = cols_settings\n",
    "    )\n",
    "    # fig.update_traces(pointpos=0)\n",
    "    display(fig)\n",
    "\n",
    "interactive_single_var_dropdown(options = cols_settings, render_function=fairness_violin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairness-multiverse-jpsnutmQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "11d6b0fec11ff4c9339ef5e7bc4c34b716123d4de08ca335068ad050c77a570c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
