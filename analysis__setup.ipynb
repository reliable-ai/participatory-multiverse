{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload the custom package\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport fairness_multiverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TO_ANALYSE = \"42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_SETTINGS = \"sett_\"\n",
    "PREFIX_EVAL = \"sett_eval_\"\n",
    "PREFIX_PERFORMANCE = \"perf_\"\n",
    "PREFIX_FAIRNESS = \"fair_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_DIR = Path(\".\") / \"output\"\n",
    "\n",
    "# Directory that will contain outputs from analysis\n",
    "ANALYSIS_OUTPUT_DIR = OUTPUT_DIR / \"analyses\" / (str(RUN_TO_ANALYSE))\n",
    "ANALYSIS_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_DIR = OUTPUT_DIR / \"runs\" / str(RUN_TO_ANALYSE) / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_fairness_metric = \"fair_main_equalized_odds_difference\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_raw = pd.read_csv(DATA_DIR / f\"agg_{RUN_TO_ANALYSE}_run_outputs.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df_settings = pd.json_normalize(\n",
    "    df_agg_raw[\"universe_settings\"].apply(json.loads)\n",
    ").add_prefix(\n",
    "    PREFIX_SETTINGS\n",
    ")\n",
    "\n",
    "df_agg_full = df_settings.join(df_agg_raw)\n",
    "df_agg_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns = df_agg_full.shape\n",
    "print(f\"The data has N = {rows} rows and N = {columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_settings = list(df_agg_full.columns[df_agg_full.columns.str.startswith(PREFIX_SETTINGS)])\n",
    "cols_eval = list(df_agg_full.columns[df_agg_full.columns.str.startswith(PREFIX_EVAL)])\n",
    "cols_non_eval = list(set(cols_settings) - set(cols_eval))\n",
    "cols_performance = list(df_agg_full.columns[df_agg_full.columns.str.startswith(PREFIX_PERFORMANCE)])\n",
    "cols_fairness = list(df_agg_full.columns[df_agg_full.columns.str.startswith(PREFIX_FAIRNESS)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_full[\"universe_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_mask = df_agg_full[\"sett_exclude_subgroups\"].isin(['keep-largest_race_1'])\n",
    "print(f\"Dropping N = {drop_mask.sum()} rows, keeping N = {(~drop_mask).sum()}\")\n",
    "\n",
    "df_agg_full = df_agg_full[~drop_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_full[\"sett_exclude_subgroups\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_full[\"sett_eval_fairness_grouping\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_full[\"sett_eval_exclude_subgroups\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_full[\"sett_eval_on_subset\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairness-multiverse-jpsnutmQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "11d6b0fec11ff4c9339ef5e7bc4c34b716123d4de08ca335068ad050c77a570c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
