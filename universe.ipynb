{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c53745c",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"dimensions\": {\n",
    "        \"scale\": \"scale\", # \"scale\", \"do-not-scale\",\n",
    "        \"encode_categorical\": \"one-hot\", # \"ordinal\", \"one-hot\"\n",
    "        \"stratify_split\": \"none\", # \"none\", \"target\", \"protected-attribute\", \"both\",\n",
    "        \"model\": \"elasticnet\", # \"logreg\", \"rf\", \"svm\", \"gbm\", \"elasticnet\"\n",
    "        \"cutoff\": [\"raw_0.5\", \"quantile_0.1\", \"quantile_0.25\"],\n",
    "        \"preprocess_age\": \"quantiles_3\", # \"none\", \"bins_10\", \"quantiles_3\", \"quantiles_4\"\n",
    "        \"preprocess_income\": \"bins_10000\", # \"none\", \"log\", \"bins_10000\", \"quantiles_3\", \"quantiles_4\"\n",
    "        \"exclude_features\": \"none\", # \"race\", \"sex\", \"race-sex\"\n",
    "        \"exclude_subgroups\": \"drop-name_race_Some Other Race alone\", # keep-all, drop-smallest_race_2, keep-largest_race_1, keep-largest_race_2, drop-name_race_Some Other Race alone\n",
    "        \"eval_fairness_grouping\": [\"majority-minority\", \"race-all\"],\n",
    "        \"eval_exclude_subgroups\": [\"exclude-in-eval\", \"keep-in-eval\"],\n",
    "        \"eval_on_subset\": [\n",
    "            \"full\",\n",
    "            # Largest PUMA region\n",
    "            \"locality-largest-only\",\n",
    "            # PUMA region w/ highest share of white people\n",
    "            \"locality-whitest-only\",\n",
    "            # PUMA regions belonging to a large city\n",
    "            \"locality-city-la\",\n",
    "            \"locality-city-sf\",\n",
    "            # Exclude military personnel from test dataset\n",
    "            \"exclude-military\",\n",
    "            # Exclude non US citizens from test dataset\n",
    "            \"exclude-non-citizens\",\n",
    "        ],\n",
    "        \"fairness_definition\": [\"sensitivity\", \"precision\"],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab72b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiversum import Universe\n",
    "\n",
    "universe_analysis = Universe(\n",
    "    settings=settings,\n",
    ")\n",
    "\n",
    "# Get the parsed universe settings\n",
    "universe = universe_analysis.dimensions\n",
    "seed = universe_analysis.seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec02d2",
   "metadata": {},
   "source": [
    "Always use the same seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe74108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "parsed_seed = int(seed)\n",
    "np.random.seed(parsed_seed)\n",
    "print(f\"Using Seed: {parsed_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08031d45",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "### (Down)load Data from Census\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f131bad",
   "metadata": {
    "tags": [
     "load-data"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from folktables import ACSDataSource\n",
    "\n",
    "data_source = ACSDataSource(\n",
    "    survey_year='2018',\n",
    "    horizon='1-Year',\n",
    "    survey='person'\n",
    ")\n",
    "\n",
    "# Use custom caching of data\n",
    "cache_dir = Path(\"data\")\n",
    "cache_dir.mkdir(exist_ok=True)\n",
    "cache_file = cache_dir / \"dataset.csv.gz\"\n",
    "if cache_file.exists():\n",
    "    print(f\"Loading data from cache: {cache_file}\")\n",
    "    dataset = pd.read_csv(cache_file)\n",
    "else:\n",
    "    # Load dataset via folktables, if necessary download from the internet\n",
    "    dataset = data_source.get_data(states=[\"CA\"], download=True)\n",
    "    # Write file to cache\n",
    "    dataset.to_csv(cache_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c309c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download additional definition data\n",
    "definition_df = data_source.get_definitions(download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0910e",
   "metadata": {},
   "source": [
    "### Perform Pre-Processing for Selected Task\n",
    "\n",
    "- **ACSIncome**: predict whether an individualâ€™s income is above $50,000, after filtering the ACS PUMS data sample to only include individuals above the age of 16, who reported usual working hours of at least 1 hour per week in the past year, and an income of at least $100. The threshold of $50,000 was chosen so that this dataset can serve as a replacement to UCI Adult, but we also offer datasets with other income cutoffs described in Appendix B.\n",
    "- **ACSPublicCoverage**: predict whether an individual is covered by public health insurance, after filtering the ACS PUMS data sample to only include individuals under the age of 65, and those with an income of less than $30,000. This filtering focuses the prediction problem on low-income individuals who are not eligible for Medicare.\n",
    "- **ACSMobility**: predict whether an individual had the same residential address one year ago, after filtering the ACS PUMS data sample to only include individuals between the ages of 18 and 35. This filtering increases the difficulty of the prediction task, as the base rate of staying at the same address is above 90% for the general population.\n",
    "- **ACSEmployment**: predict whether an individual is employed, after filtering the ACS PUMS data sample to only include individuals between the ages of 16 and 90.\n",
    "- **ACSTravelTime**: predict whether an individual has a commute to work that is longer than 20 minutes, after filtering the ACS PUMS data sample to only include individuals who are employed and above the age of 16. The threshold of 20 minutes was chosen as it is the US-wide median travel time to work in the 2018 ACS PUMS data release\n",
    "\n",
    "- The selected story & task has implications for which fairness metric makes the most sense in the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6b3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from folktables import generate_categories\n",
    "from folktables import ACSPublicCoverage\n",
    "\n",
    "# Normally you would create the task with the following snippet\n",
    "# features, label, group = ACSEmployment.df_to_numpy(acs_data)\n",
    "# But this severly limits us in regards to how many protected\n",
    "# groups we can examine and further removes feature lables\n",
    "\n",
    "task = deepcopy(ACSPublicCoverage)\n",
    "\n",
    "# Additional features to extract, that are not part of the task\n",
    "extra_feature_cols = [\"PUMA\"]\n",
    "task._features.extend(extra_feature_cols)\n",
    "\n",
    "categories = generate_categories(features=task.features, definition_df=definition_df)\n",
    "features_org, label_org, group_org = task.df_to_pandas(dataset, categories=categories)\n",
    "\n",
    "# Keep a reference to the original state of featuers\n",
    "features = features_org.copy()\n",
    "\n",
    "# Immediately remove the extra features before they could leak into the task\n",
    "features.drop(columns=extra_feature_cols, inplace=True)\n",
    "extra_features = features_org[extra_feature_cols].copy()\n",
    "\n",
    "label = label_org.copy()\n",
    "group = group_org.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the data\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a4746",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4bdec58",
   "metadata": {},
   "source": [
    "### Exclude Protected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c6f062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this will alwqys be n >= 1, even if empty!\n",
    "excluded_features = universe[\"exclude_features\"].split(\"-\")\n",
    "excluded_features_dictionary = {\n",
    "    \"race\": \"RAC1P\",\n",
    "    \"sex\": \"SEX\",\n",
    "    \"immigration\": \"NATIVITY\",\n",
    "}\n",
    "\n",
    "# Code nice names to column names\n",
    "excluded_feature_columns = [\n",
    "    excluded_features_dictionary[f] for f in excluded_features if len(f) > 0 and f != \"none\"\n",
    "]\n",
    "\n",
    "if len(excluded_feature_columns) > 0:\n",
    "    print(f\"Dropping features: {excluded_feature_columns}\")\n",
    "    features.drop(excluded_feature_columns, axis=1, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11bb9c9a",
   "metadata": {},
   "source": [
    "### Continuous Variables: Binning / Log-Scaling / Keeping Them As-Is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b834bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import ceil, floor\n",
    "from typing import List, Optional, Tuple\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FunctionTransformer, make_pipeline\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "def continuous_var_will_be_binned(configuration: str):\n",
    "    return configuration.startswith((\"quantiles\", \"bins\"))\n",
    "\n",
    "# Modified version of pandas.cut, that also supports DataFrames instead of just Series\n",
    "def cut_df(df, **kwargs) -> pd.DataFrame:\n",
    "    # Adapted from https://datascience.stackexchange.com/questions/75787/how-to-use-columntransformer-and-functiontransformer-to-apply-the-same-function\n",
    "    if isinstance(df, pd.Series):\n",
    "        return pd.cut(df, **kwargs)\n",
    "    elif isinstance(df, pd.DataFrame):\n",
    "        return df.apply(pd.cut, axis=0, **kwargs)\n",
    "    else:\n",
    "        raise \"Unsupported type of data in cut_df\"\n",
    "\n",
    "def preprocess_continuous(\n",
    "    source_data: pd.DataFrame, column_name: str, configuration: str\n",
    ") -> Tuple[Optional[ColumnTransformer], Optional[List[str]]]:\n",
    "    \"\"\"Preprocess a continuous variable.\n",
    "\n",
    "    Args:\n",
    "        source_data: The source data containing the variable to be\n",
    "            preprocessed.\n",
    "        column_name: The name of the column to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the ColumnTransformer to be used for preprocessing\n",
    "        and the list of binned values (if applicable).\n",
    "    \"\"\"\n",
    "    if configuration == \"none\":\n",
    "        # Skip transformation if \"none\" is specified\n",
    "        return (None, None)\n",
    "    elif configuration == \"log\":\n",
    "        transformer = make_pipeline(\n",
    "            # Calculate the log (+1 to gracefully handle 0)\n",
    "            # Since negative values are undefined for log, we replace them with 0\n",
    "            # (NAs cannot be handled by all algorithms)\n",
    "            FunctionTransformer(lambda df: np.log1p(df.astype(\"float\")).fillna(0))\n",
    "        )\n",
    "        binned_values = None\n",
    "    elif continuous_var_will_be_binned(configuration=configuration):\n",
    "        method, value = configuration.split(\"_\")\n",
    "        if method == \"quantiles\":\n",
    "            n_bins = int(value)\n",
    "            transformer = KBinsDiscretizer(\n",
    "                n_bins=n_bins,\n",
    "                encode=\"ordinal\",\n",
    "                strategy=\"quantile\",\n",
    "                random_state=np.random.randint(10000)\n",
    "            )\n",
    "        elif method == \"bins\":\n",
    "            step = int(value)\n",
    "            round_min = floor(source_data[column_name].min() / step) * step\n",
    "            round_max = ceil(source_data[column_name].max() / step) * step\n",
    "            bins = list(range(round_min, round_max, step)) + [round_max]\n",
    "\n",
    "            print(\n",
    "                f\"Generated bins transformer for {column_name} with the following bins: {bins}\"\n",
    "            )\n",
    "\n",
    "            transformer = FunctionTransformer(\n",
    "                cut_df, kw_args={\"bins\": bins, \"labels\": False, \"retbins\": False}\n",
    "            )\n",
    "            n_bins = len(bins)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Unsupported method for preprocessing continuous variable: \" + method\n",
    "            )\n",
    "\n",
    "        binned_values = list(range(n_bins))\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"Unsupported configuration for preprocessing continuous variable: \"\n",
    "            + configuration\n",
    "        )\n",
    "\n",
    "    column_transformer = ColumnTransformer(\n",
    "        [(f\"bin_{column_name}_{configuration}\", transformer, [column_name])],\n",
    "        remainder=\"passthrough\",\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "    column_transformer.set_output(transform=\"pandas\")\n",
    "    return (column_transformer, binned_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8517e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "transformer_age, bins_age = preprocess_continuous(source_data=features, column_name=\"AGEP\", configuration=universe[\"preprocess_age\"])\n",
    "transformer_income, bins_income = preprocess_continuous(source_data=features, column_name=\"PINCP\", configuration=universe[\"preprocess_income\"])\n",
    "\n",
    "continuous_processor = make_pipeline(\n",
    "    transformer_age,\n",
    "    transformer_income\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6a8beb2",
   "metadata": {},
   "source": [
    "### Categorical Variables: One-Hot or Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc7da117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "all_categorical_columns = list(set(categories.keys()).intersection(set(features.columns)))\n",
    "\n",
    "# For which columns is ordinal encoding even an option?\n",
    "categorical_columns_to_transform = [\n",
    "    'SCHL',\n",
    "    # 'MAR',\n",
    "    # 'SEX',\n",
    "    # 'DIS',\n",
    "    # 'ESP',\n",
    "    # 'CIT',\n",
    "    # 'MIG',\n",
    "    'MIL',\n",
    "    # 'ANC',\n",
    "    # 'NATIVITY',\n",
    "    # 'DEAR',\n",
    "    # 'DEYE',\n",
    "    # 'DREM',\n",
    "    # 'ESR',\n",
    "    # 'ST',\n",
    "    # 'FER',\n",
    "    # 'RAC1P'\n",
    "]\n",
    "\n",
    "# Support to-be-binned continuous variables\n",
    "def add_binned_variable_to_categorical_transformation(colname, values):\n",
    "    if values is not None:\n",
    "        categorical_columns_to_transform.append(colname)\n",
    "        categories[colname] = {val: val for val in values}\n",
    "\n",
    "add_binned_variable_to_categorical_transformation(\"AGEP\", bins_age)\n",
    "add_binned_variable_to_categorical_transformation(\"PINCP\", bins_income)\n",
    "\n",
    "def nested_list(all_categories, columns_to_use):\n",
    "    categories = { col: all_categories[col] for col in columns_to_use }\n",
    "    # Create a nested list from the categories dict\n",
    "    categories_list = [[v for k, v in mapping.items()] for column, mapping in categories.items()]\n",
    "    return categories_list\n",
    "\n",
    "if (universe[\"encode_categorical\"] == \"ordinal\"):\n",
    "    categorical_transformer = OrdinalEncoder(\n",
    "        categories = nested_list(categories, categorical_columns_to_transform),\n",
    "    )\n",
    "elif (universe[\"encode_categorical\"] == \"one-hot\"):\n",
    "    categorical_transformer = OneHotEncoder(\n",
    "        categories = nested_list(categories, categorical_columns_to_transform),\n",
    "        sparse_output=False\n",
    "    )\n",
    "else:\n",
    "    raise \"Unsupported universe option for encode_categorical\"\n",
    "\n",
    "# One-Hot Encode all other cateogircal columns\n",
    "other_categorical_columns = list(set(all_categorical_columns) - set(categorical_columns_to_transform))\n",
    "other_transformer = OneHotEncoder(\n",
    "    categories = nested_list(categories, other_categorical_columns),\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "categorical_preprocessor = ColumnTransformer([\n",
    "        (\"encode_categorical\", categorical_transformer, categorical_columns_to_transform),\n",
    "        (\"encode_categorical_rest\", other_transformer, other_categorical_columns),\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a533a3",
   "metadata": {},
   "source": [
    "## Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b62b1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select stratification strategy\n",
    "if universe[\"stratify_split\"] == \"none\":\n",
    "    stratify = None\n",
    "elif universe[\"stratify_split\"] == \"target\":\n",
    "    stratify = label\n",
    "elif universe[\"stratify_split\"] == \"protected-attribute\":\n",
    "    stratify = features_org[\"RAC1P\"]\n",
    "elif universe[\"stratify_split\"] == \"both\":\n",
    "    # Concatinate both columns\n",
    "    stratify = features_org[\"RAC1P\"].astype(str) + \"-\" + label[\"PUBCOV\"].astype(str)\n",
    "\n",
    "stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea5c57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(\n",
    "    X_train, X_test,\n",
    "    y_train, y_true,\n",
    "    group_train, group_test,\n",
    "    org_train, org_test\n",
    ") = train_test_split(\n",
    "    features,\n",
    "    label,\n",
    "    group,\n",
    "    features_org,\n",
    "    test_size=0.2,\n",
    "    # Note: The analysis originally used two distinct seeds, one for numpy (defaulting to 2023) and one for the train_test_split (defaulting to 0).\n",
    "    # To allow for exact reproducibility of the original results, as well as specification of only a single seed we base this second seed off the first one.\n",
    "    # If you adapt this code for your own analysis feel free to remove this line and replace it e.g. with e.g. a call to numpy.random.randint.\n",
    "    random_state=abs(parsed_seed - 2023),\n",
    "    stratify=stratify\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f0e9037",
   "metadata": {},
   "source": [
    "## Post-Splitting Processing\n",
    "\n",
    "If e.g. only train data is affected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f46a11",
   "metadata": {},
   "source": [
    "### Exclude Certain Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract configuration\n",
    "exclude_subgroups_config = universe[\"exclude_subgroups\"].split(\"_\")\n",
    "if len(exclude_subgroups_config) == 1:\n",
    "    exclude_subgroups_config = (exclude_subgroups_config[0], None, None)\n",
    "excl_subgroups_method, excl_subgroup_colname, excl_subgroups_value = exclude_subgroups_config\n",
    "\n",
    "if excl_subgroup_colname == \"race\":\n",
    "    excl_subgroup_column = \"RAC1P\"\n",
    "    excl_subgroup_counts = org_train[excl_subgroup_column].value_counts()\n",
    "elif excl_subgroups_method != \"keep-all\":\n",
    "    raise Exception(\"Unsupported configuration for exclude_subgroups:\" + universe[\"exclude_subgroups\"])\n",
    "\n",
    "if excl_subgroups_method == \"keep-all\":\n",
    "    # Don't need to do anything\n",
    "    excl_subgroup_column = None\n",
    "    excl_subgroup_values = []\n",
    "else:\n",
    "    if excl_subgroups_method == \"drop-smallest\":\n",
    "        drop_smallest_n = int(excl_subgroups_value)\n",
    "        excl_subgroup_values = list(excl_subgroup_counts.tail(drop_smallest_n).index)\n",
    "    elif excl_subgroups_method == \"keep-largest\":\n",
    "        keep_largest_n = int(excl_subgroups_value)\n",
    "        excl_subgroup_values = list(excl_subgroup_counts.tail(\n",
    "            len(excl_subgroup_counts) - keep_largest_n\n",
    "        ).index)\n",
    "    elif excl_subgroups_method == \"drop-name\":\n",
    "        excl_subgroup_values = [excl_subgroups_value]\n",
    "    elif excl_subgroups_method == \"keep-names\":\n",
    "        excl_subgroup_values = list(excl_subgroup_counts.index)\n",
    "        for group_to_keep in excl_subgroups_value.split(\"-\"):\n",
    "            excl_subgroup_values.remove(group_to_keep)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported configuration for exclude_subgroups:\" + universe[\"exclude_subgroups\"])\n",
    "\n",
    "    if excl_subgroup_column is not None:\n",
    "        print(f\"Dropping values: {excl_subgroup_values}\")\n",
    "        keep_rows_mask = ~org_train[excl_subgroup_column].isin(excl_subgroup_values)\n",
    "\n",
    "    n_rows_to_drop = (~keep_rows_mask).sum()\n",
    "    if n_rows_to_drop > 0:\n",
    "        print(f\"Dropping N = {n_rows_to_drop} ({n_rows_to_drop / len(keep_rows_mask):.2%}) rows from {excl_subgroup_colname}\")\n",
    "        X_train = X_train[keep_rows_mask]\n",
    "        y_train = y_train[keep_rows_mask]\n",
    "        group_train = group_train[keep_rows_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd0e0d",
   "metadata": {},
   "source": [
    "## Fitting the Model\n",
    "\n",
    "Select which model to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dbcf50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "if (universe[\"model\"] == \"logreg\"):\n",
    "    model = LogisticRegression(random_state=np.random.randint(10000))\n",
    "elif (universe[\"model\"] == \"rf\"):\n",
    "    model = RandomForestClassifier(random_state=np.random.randint(10000))\n",
    "elif (universe[\"model\"] == \"svm\"):\n",
    "    model = SVC(random_state=np.random.randint(10000))\n",
    "elif (universe[\"model\"] == \"gbm\"):\n",
    "    model = GradientBoostingClassifier(random_state=np.random.randint(10000))\n",
    "elif (universe[\"model\"] == \"elasticnet\"):\n",
    "    model = LogisticRegression(penalty = 'elasticnet', solver = 'saga', l1_ratio = 0.5, random_state=np.random.randint(10000))\n",
    "else:\n",
    "    raise \"Unsupported universe.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8422ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiversum.universe import predict_w_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"continuous_processor\", continuous_processor),\n",
    "    (\"categorical_preprocessor\", categorical_preprocessor),\n",
    "    (\"scale\", StandardScaler() if universe[\"scale\"] == \"scale\" else None),\n",
    "    (\"model\", model),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)\n",
    "y_pred_default = predict_w_threshold(y_prob, 0.5)\n",
    "\n",
    "# Naive prediction\n",
    "accuracy_score(y_true = y_true, y_pred = y_pred_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c72f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea335dd0",
   "metadata": {},
   "source": [
    "## (Fairness) Metrics\n",
    "\n",
    "- Using [Fairlearn](https://fairlearn.org/v0.8/quickstart.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1702fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "colname_to_bin = \"RAC1P\"\n",
    "majority_value = features_org[colname_to_bin].mode()[0]\n",
    "\n",
    "org_test[\"majmin\"] = np.where(org_test[colname_to_bin] == majority_value, \"majority\", \"minority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88e12cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_universe = universe.copy()\n",
    "example_universe[\"cutoff\"] = example_universe[\"cutoff\"][0]\n",
    "example_universe[\"eval_fairness_grouping\"] = example_universe[\"eval_fairness_grouping\"][0]\n",
    "example_universe[\"fairness_definition\"] = example_universe[\"fairness_definition\"][0]\n",
    "fairness_dict, metric_frame = universe_analysis.compute_sub_universe_metrics(\n",
    "    example_universe,\n",
    "    y_pred_prob=y_prob,\n",
    "    y_test=y_true,\n",
    "    org_test=org_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_universes = universe_analysis.generate_sub_universes()\n",
    "len(sub_universes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a6ebd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needs to be run once, so disabled for now\n",
    "\n",
    "# Calculate PUMA area with the highest share of people with PUBCOV == 1\n",
    "# puma_coverage = org_train.join(y_train).groupby(\"PUMA\")[\"PUBCOV\"].mean()\n",
    "# puma_coverage_highest = puma_coverage.sort_values(ascending=False).head(1)\n",
    "# puma_coverage_highest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfc62dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Uses excl_subgroup_column and values from the global scope\n",
    "\n",
    "def filter_sub_universe_data(sub_universe, org_test):\n",
    "  # Generate an all True mask to start with\n",
    "  keep_rows_mask = np.ones(org_test.shape[0], dtype=bool)\n",
    "\n",
    "  # Potentially remove any subgroups from the test set\n",
    "  if (sub_universe[\"eval_exclude_subgroups\"] == \"exclude-in-eval\"):\n",
    "    if excl_subgroup_column is not None:\n",
    "      assert excl_subgroup_values is not None\n",
    "\n",
    "      exclude_subgroup_eval_mask = ~org_test[excl_subgroup_column].isin(excl_subgroup_values)\n",
    "      keep_rows_mask = keep_rows_mask & exclude_subgroup_eval_mask\n",
    "\n",
    "      n_rows_to_drop = (~exclude_subgroup_eval_mask).sum()\n",
    "      print(f\"[drop subgroups] Dropping N = {n_rows_to_drop} ({n_rows_to_drop / len(keep_rows_mask):.2%}) rows from {excl_subgroup_colname}\")\n",
    "  elif (sub_universe[\"eval_exclude_subgroups\"] == \"keep-in-eval\"):\n",
    "    pass\n",
    "  else:\n",
    "    raise \"Unsupported eval_exclude_subgroups\"\n",
    "\n",
    "  # Potentially use a smaller and more \"convenient\" subset of the data to do evalaution on\n",
    "  if (sub_universe[\"eval_on_subset\"] == \"full\"):\n",
    "    pass\n",
    "  else:\n",
    "    if sub_universe[\"eval_on_subset\"].startswith(\"locality\"):\n",
    "      # Filter based on locality / region\n",
    "      # Step 1: Decide which regions to keep\n",
    "      if (sub_universe[\"eval_on_subset\"] == \"locality-largest-only\"):\n",
    "        # Use the largest PUMA region\n",
    "        puma_regions_to_keep = [org_test[\"PUMA\"].value_counts().idxmax()]\n",
    "      elif (sub_universe[\"eval_on_subset\"] == \"locality-most-privileged\"):\n",
    "        # Use the PUMA region the highest number of PUBCOV = 1 (done in cell above)\n",
    "        puma_regions_to_keep = [2904] # 2904 -> 62.8% of PUBCOV\n",
    "\n",
    "      elif (sub_universe[\"eval_on_subset\"] == \"locality-whitest-only\"):\n",
    "        # Find the majority class on the prot. attribute\n",
    "        majority_class = org_test[\"RAC1P\"].value_counts().index[0]\n",
    "        majority_class\n",
    "\n",
    "        # Find the PUMA region with the highest share of the majority class\n",
    "        counts = pd.DataFrame()\n",
    "        counts[\"full\"] = org_test[\"PUMA\"].value_counts(sort=False)\n",
    "        counts[\"majority\"] = org_test[org_test[\"RAC1P\"] == majority_class][\"PUMA\"].value_counts(sort=False)\n",
    "        counts[\"fraction\"] = counts[\"majority\"] / counts[\"full\"]\n",
    "\n",
    "        # Use the PUMA region with the highest share of the majority class\n",
    "        majority_puma_id = counts.sort_values(by=\"fraction\", ascending=False).index[0]\n",
    "        puma_regions_to_keep = [majority_puma_id]\n",
    "      elif (sub_universe[\"eval_on_subset\"] == \"locality-city-la\"):\n",
    "        puma_regions_to_keep = list(range(3701, 3769+1))\n",
    "      elif (sub_universe[\"eval_on_subset\"] == \"locality-city-sf\"):\n",
    "        puma_regions_to_keep = list(range(7501, 7507+1))\n",
    "\n",
    "      # Step 2: Keep only those regions\n",
    "      print(f\"Keeping the following PUMA regions: {puma_regions_to_keep}\")\n",
    "      eval_on_subset_mask = org_test[\"PUMA\"].isin(puma_regions_to_keep)\n",
    "    elif (sub_universe[\"eval_on_subset\"] == \"exclude-military\"):\n",
    "      # Only keep non-military personnel\n",
    "      eval_on_subset_mask = (org_test[\"MIL\"].isin([\"Never served in the military\", \"N/A (less than 17 years old)\"]))\n",
    "    elif (sub_universe[\"eval_on_subset\"] == \"exclude-non-citizens\"):\n",
    "      # Only keep US citizens\n",
    "      eval_on_subset_mask = ~(org_test[\"CIT\"] == \"Not a citizen of the U.S.\")\n",
    "    else:\n",
    "      raise \"Unsupported eval_on_subset\"\n",
    "\n",
    "    keep_rows_mask = keep_rows_mask & eval_on_subset_mask\n",
    "\n",
    "    n_rows_to_drop = (~eval_on_subset_mask).sum()\n",
    "    print(f\"[subset] Dropping N = {n_rows_to_drop} ({n_rows_to_drop / len(keep_rows_mask):.2%}) rows\")\n",
    "\n",
    "  n_rows_to_drop = (~keep_rows_mask).sum()\n",
    "  print(f\"[TOTAL] Dropping N = {n_rows_to_drop} ({n_rows_to_drop / len(keep_rows_mask):.2%}) rows. Final size: {keep_rows_mask.sum()}.\")\n",
    "\n",
    "  return keep_rows_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4677b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.metrics import (\n",
    "    false_positive_rate,\n",
    "    false_negative_rate,\n",
    "    selection_rate,\n",
    "    count\n",
    ")\n",
    "from fairlearn.metrics import (\n",
    "    equalized_odds_difference,\n",
    "    equalized_odds_ratio,\n",
    "    demographic_parity_difference,\n",
    "    demographic_parity_ratio,\n",
    ")\n",
    "from multiversum.universe import add_dict_to_df, flatten_dict\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"balanced accuracy\": balanced_accuracy_score,\n",
    "    \"f1\": f1_score,\n",
    "    \"precision\": precision_score, # = ppv\n",
    "    \"recall\": recall_score, # = sensitivity, tpr\n",
    "    \"false positive rate\": false_positive_rate,\n",
    "    \"false negative rate\": false_negative_rate,\n",
    "    \"selection rate\": selection_rate,\n",
    "    \"count\": count,\n",
    "}\n",
    "\n",
    "fairness_metrics = {\n",
    "    \"equalized_odds_difference\": equalized_odds_difference,\n",
    "    \"equalized_odds_ratio\": equalized_odds_ratio,\n",
    "    \"demographic_parity_difference\": demographic_parity_difference,\n",
    "    \"demographic_parity_ratio\": demographic_parity_ratio,\n",
    "}\n",
    "\n",
    "def compute_metrics(\n",
    "        sub_universe: Dict,\n",
    "        y_pred_prob: pd.Series,\n",
    "        y_test: pd.Series,\n",
    "        org_test: pd.DataFrame,\n",
    "    ) -> Tuple[dict, dict]:\n",
    "        \"\"\"\n",
    "        Computes a set of metrics for a given sub-universe.\n",
    "\n",
    "        Args:\n",
    "            sub_universe: A dictionary containing the parameters for the\n",
    "                sub-universe.\n",
    "            y_pred_prob: A pandas series containing the predicted\n",
    "                probabilities.\n",
    "            y_test: A pandas series containing the true labels.\n",
    "            org_test: A pandas dataframe containing the test data, including\n",
    "                variables that were not used as features.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing two dicst: explicit fairness metrics and\n",
    "                performance metrics split by fairness groups.\n",
    "        \"\"\"\n",
    "        # Determine cutoff for predictions\n",
    "        cutoff_type, cutoff_value = sub_universe[\"cutoff\"].split(\"_\")\n",
    "        cutoff_value = float(cutoff_value)\n",
    "\n",
    "        if cutoff_type == \"raw\":\n",
    "            threshold = cutoff_value\n",
    "        elif cutoff_type == \"quantile\":\n",
    "            probabilities_true = y_pred_prob[:, 1]\n",
    "            threshold = np.quantile(probabilities_true, cutoff_value)\n",
    "\n",
    "        fairness_grouping = sub_universe[\"eval_fairness_grouping\"]\n",
    "        if fairness_grouping == \"majority-minority\":\n",
    "            fairness_group_column = \"majmin\"\n",
    "        elif fairness_grouping == \"race-all\":\n",
    "            fairness_group_column = \"RAC1P\"\n",
    "\n",
    "        y_pred = predict_w_threshold(y_pred_prob, threshold)\n",
    "\n",
    "        # Compute fairness metrics\n",
    "        fairness_dict = {\n",
    "            name: metric(\n",
    "                y_true=y_test,\n",
    "                y_pred=y_pred,\n",
    "                sensitive_features=org_test[fairness_group_column],\n",
    "            )\n",
    "            for name, metric in fairness_metrics.items()\n",
    "        }\n",
    "\n",
    "        # Compute \"normal\" metrics (but split by fairness column)\n",
    "        metric_frame = MetricFrame(\n",
    "            metrics=metrics,\n",
    "            y_true=y_test,\n",
    "            y_pred=y_pred,\n",
    "            sensitive_features=org_test[fairness_group_column],\n",
    "        )\n",
    "\n",
    "        # Compute the maximum difference on the chosen metric\n",
    "        fairness_definition = sub_universe[\"fairness_definition\"]\n",
    "        if fairness_definition == \"sensitivity\": # sensitivity = recall = true positive rate\n",
    "            metric_col = \"recall\"\n",
    "            pass\n",
    "        elif fairness_definition == \"precision\":\n",
    "            metric_col = \"precision\"\n",
    "        else:\n",
    "            raise \"Unsupported fairness definition: \" + fairness_definition\n",
    "        fairness_dict[\"custom_fairness_metric\"] = metric_frame.difference()[metric_col]\n",
    "\n",
    "        return (fairness_dict, metric_frame)\n",
    "\n",
    "def visit_sub_universe(\n",
    "    sub_universe, y_pred_prob, y_test, org_test, filter_data\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Visit a sub-universe and compute the metrics for it.\n",
    "\n",
    "    Sub-universes correspond to theoretically distinct universes of\n",
    "    decisions, which can be computed without re-fitting a model. The\n",
    "    distinction has only been made to improve performance by not having to\n",
    "    compute these universes from scratch.\n",
    "\n",
    "    Args:\n",
    "        sub_universe: A dictionary containing the parameters for the\n",
    "            sub-universe.\n",
    "        y_pred_prob: A pandas series containing the predicted\n",
    "            probabilities.\n",
    "        y_test: A pandas series containing the true labels.\n",
    "        org_test: A pandas dataframe containing the test data, including\n",
    "            variables that were not used as features.\n",
    "        filter_data: A function that filters data for each sub-universe.\n",
    "            The function is called for each sub-universe with its\n",
    "            respective settings and expected to return a pandas Series\n",
    "            of booleans.\n",
    "\n",
    "    Returns:\n",
    "        A pandas dataframe containing the metrics for the sub-universe.\n",
    "    \"\"\"\n",
    "    final_output = universe_analysis._add_universe_info(\n",
    "        pd.DataFrame(index=[universe_analysis.universe_id]),\n",
    "        overwrite_dimensions=sub_universe\n",
    "    )\n",
    "\n",
    "    data_mask = filter_data(\n",
    "        sub_universe=sub_universe,\n",
    "        org_test=org_test\n",
    "    )\n",
    "    test_size_n = data_mask.sum()\n",
    "    final_output[\"test_size_n\"] = test_size_n\n",
    "    final_output[\"test_size_frac\"] = data_mask.sum() / len(data_mask)\n",
    "\n",
    "    # Only compute metrics if we have a sample size to calculate it on\n",
    "    if test_size_n > 0:\n",
    "        # Compute metrics\n",
    "        fairness_dict, metric_frame = compute_metrics(\n",
    "            sub_universe,\n",
    "            y_pred_prob[data_mask],\n",
    "            y_test[data_mask],\n",
    "            org_test[data_mask],\n",
    "        )\n",
    "\n",
    "        # Add main fairness metrics to final_output\n",
    "        final_output = add_dict_to_df(final_output, fairness_dict, prefix=\"fair_main_\")\n",
    "        final_output = add_dict_to_df(\n",
    "            final_output, dict(metric_frame.overall), prefix=\"perf_ovrl_\"\n",
    "        )\n",
    "        # Add group metrics to final output\n",
    "        final_output = add_dict_to_df(\n",
    "            final_output, flatten_dict(metric_frame.by_group), prefix=\"perf_grp_\"\n",
    "        )\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6976413",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_universes = universe_analysis.generate_sub_universes()\n",
    "\n",
    "final_outputs = list()\n",
    "for sub_universe in sub_universes:\n",
    "    final_outputs.append(\n",
    "        visit_sub_universe(\n",
    "            sub_universe=sub_universe,\n",
    "            y_pred_prob=y_prob,\n",
    "            y_test=y_true,\n",
    "            org_test=org_test,\n",
    "            filter_data=filter_sub_universe_data,\n",
    "        ).reset_index(drop=True)\n",
    "    )\n",
    "final_output = pd.concat(final_outputs)\n",
    "\n",
    "# Write the final output file\n",
    "universe_analysis.save_data(\n",
    "    final_output,\n",
    "    add_info=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e543698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
